# 1.5 Fetching a URL

Go provides a collection of packages, grouped under net, that make it easy to
send and receive information through the Internet, make low-level network
connections, and set up servers, for which Go's concurrency features are
particularly useful.

Here's a program to illustrate the minimum necessary to retrieve information
over HTTP.
It is a simple program that fetches the content of each specified URL and prints
it as uninterpreted text.

```go
// Mem Fetch is a simple HTTP service to practive Go's net package

package main

import (
    "fmt"
    "io/ioutil"
    "net/http"
    "os"
)

func main() {
    url := os.Args[1:][0]
    resp, _ := http.Get(url)
    b, _ := ioutil.ReadAll(resp.Body)
    resp.Body.Close()
    fmt.Printf("%s", b)
}

```

Introducing two new packages, `net/http` and `io/ioutil`.

The `http.Get` function makes an HTTP request and, if there is no error, returns
the result in the response `struct resp`. The `Body` field of the `resp` contains
the server response as a readable stream. Next, `ioutil.ReadAll` reads the entire
response; the result is stored in `b`. The `Body` stream is closed to avoid
leaking resources.

**Exercise 1.7:** The function call `io.Copy(dst, src)` reads from `src` and writes
to `dst`. Use it instead of `ioutil.ReadAll` to copy the response body to `os.Stdout`
without requiring a buffer large enough to hold the entire stream. Be sure to check
the error result of `io.Copy`.

```go
// mem_fetch is a program to practice HTTP calls in Go

package main

import (
	"fmt"
	"io"
	"net/http"
	"os"
)

func main() {
	url := "https://jsonplaceholder.typicode.com/todos"
	resp, err := http.Get(url)
	if err != nil {
		fmt.Fprintf(os.Stderr, "fetch: %v", err)
		os.Exit(1)
	}
	_, err = io.Copy(os.Stdout, resp.Body)
	if err != nil {
		fmt.Fprintf(os.Stderr, "copy: %v", err)
	}
	resp.Body.Close()
}

```
