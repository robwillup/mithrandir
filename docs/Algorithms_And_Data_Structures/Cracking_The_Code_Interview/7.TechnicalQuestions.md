# Technical Questions

If you just read through problems and solutions, you won't learn anything because that is similar to trying to learn calculus by reading a problem and its solutions. You need to practice solving problems. Memorizing solutions won't help much.

For each problem you might encounter, do the following:

1. Try to solve the problem on your own.
   1. Push yourself to develop a solutions with as little help as possible.
   2. Make sure to think about space and time efficiency.
2. Write the code on paper.
   1. Coding on a computer offers luxuries such as syntax highlighting, code completion, and quick debugging. Coding on paper does not.
   2. Get used to this and to how slow it is to write and edit code by coding on paper.
3. Test your code - on paper.
   1. This means testing the general cases, base cases, error cases, worst cases, edge cases, and so on.
4. Type your paper code as-is into a computer.
   1. You will probably make a bunch of mistakes. Start a lis of all the errors so that you can focus on learning to correct them.

## What you need to know

This a a baseline of knowledge you need to have.

### Core Data Structures, Algorithms, and Concepts

Here is a list of the absolute, must-have knowledge:

* Data Structures
  * Linked Lists
  * Trees, Tries, & Graphs
  * Stacks & Queues
  * Heaps
  * Vectors / ArrayLists
  * Hash Tables
* Algorithms
  * Breadth-First Search
  * Depth-First Search
  * Binary Search
  * Merge Sort
  * Quick Sort
* Concepts
  * Bit Manipulation
  * Memory (Stack vs. Heap)
  * Recursion
  * Dynamic Programming
  * Big O Time & Space

For each of these topics, make sure you understand how to use and implement them and, where applicable, the time and space complexity.

Practicing implementing the data structures and algorithm on paper, and then on a computer, is also a great exercise. It will help you understand the internals of the data structures work.

In particular, hash tables are an extremely important topic. Make sure you are very comfortable with this data structure.

### Powers of 2 Table

The table below is useful for many questions involving scalability or any soft of memory limitation. Be comfortable deriving this table and memorize it.

|Powers of 2|Exact Value (x)   |Approx. Value|X Bytes into MB, GB, etc.|
|:---------:|:----------------:|:-----------:|:-----------------------:|
|7          |128               |             |                         |
|8          |256               |             |                         |
|10         |1024              |1 thousand   |1 KB                     |
|16         |65,536            |             |64 KB                    |
|20         |1,048,576         |1 million    |1 MB                     |
|30         |1,073,741,824     |1 billion    |1 GB                     |
|32         |4,294,967,296     |             |4 GB                     |
|40         |1,099,511,627,776 |1 trillion   |1 TB                     |

For example, you could use this table to quickly compute that a bit vector mapping every 32-bit integer to a boolean value could fit in memory on a typical machine. There are 2³² such integers. Because each integer takes one bit in this bit vector, we need 2³² bits (or 2²⁹ bytes) to store this mapping. That's about a gigabyte of memory, which can easily be held in memory on a typical machine.

### Walking Through a Problem

The below map/flowchart walks you through how to solve a problem.

1. Listen / Read
   1. Pay very close attention to any information in the problem. You probably need all of it for an optimal algorithm.
2. Example
   1. Most examples are too small or are special cases. Debug you example. Is there any way it's a special case? Is it big enough?
3. Brute Force
   1. Get a brute-force solution as soon as possible. Don't worry about developing an efficient algorithm yet. State a naive algorithm and its runtime, then optimize from there. Don't code yet though!
4. Optimize
   1. Walk through your brute force with BUD optimization
      1. Bottlenecks
      2. Unnecessary Work
      3. Duplicated Word
   2. Look for any unused info. You usually need all the information in a problem.
   3. Solve it manually on an example, then reverse engineer your thought process. How did I solve this?
   4. Solve it "incorrectly" and then think about why the algorithm fails. Can you fix those issues?
   5. Make a time vs. space tradeoff. Hash tables are especially useful!
5. Walk Through
   1. Now that you have an optimal solution, walk through your approach in detail. Make sure you understand each detail before you start coding.
6. Implement
   1. Your goal is to write beautiful code. Modularize your code from the beginning and refactor to clean up anything that ins't beautiful.
7. Test
   1. Conceptual test. Walk through your code like you would for a detailed code review.
   2. Unusual or non-standard code.
   3. Hot spots, like arithmetic and null nodes.
   4. Small test cases. It's much faster then a big test case and just as effective.
   5. Special cases and edge cases.
   6. When you find bugs fix them carefully.

It's common when solving a problem that people will read the question and a few minutes later they've already written a good portion of the code but forgot important details. Try to mentally memory these details.

Draw an example, don't just try to solve the problem in your head. The example needs to be good, not too
small, not too generic, not a perfect case that is easy to solve. The example must be:

* Specific. It should use real numbers or strings (if applicable to the problem)
* Sufficiently large. Most examples are too small
* Not a special case. Try edge cases instead.

Some candidates don't state the brute force because they think it's both obvious and terrible. But here's the
thing: Even if it's obvious for you, it's not necessarily obvious for all candidates. You don't want your
interviewer to think that you're struggling to see even the easy solution.

It's okay that this initial solution is terrible. Explain what the space and time complexity is, and then
dive into improvements.

Despite being possibly slow, a brute force algorithm is valuable to discuss. It's a starting point for optimizations, and it helps you wrap your head around the problem.

Some techniques for optimizing algorithms are:

1. Look for any unused information. Is the array already sorted?
2. Use a fresh example. Sometimes, just seeing a different example will unclog your mind or help you see a
a pattern in the problem
3. Make time vs. space tradeoff. Sometimes storing extra state about the problem can help optimize the
runtime.
4. Precompute information. Is there any way that you can reorganize the data or compute some values upfront
that will help save time in the long run?
6. Use a hash table. Hash tables are widely used in interview questions and should be at the top of your mind.
7. Think about the best conceivable runtime.

Once you've nailed down an optimal algorithm, don't just dive into coding. Take time to solidify your
understanding of the algorithm.

Go slow and make sure that you get it as close to "perfect" in the beginning as possible.

If you don't understand exactly what you're about to write, you'll struggle to code it. It will take you longer to finish the code, and you're more likely to make major errors.

Take time to understand.

Take time!

Be rigorous.

When implementing your algorithm, remember that every detail counts. Write beautiful code.

Beautiful code means:

* Modularized code.
* Error checks.
* Use other classes/structs where appropriate
* Good variable names.

To test your algorithm try this approach:

1. Conceptual test: read and analyze each line of code. Does the code do what you think it should do?
2. Weird looking code. Thinks can easily be confusing.
3. Hot spots. Thinks that could easily cause problems:
   1. base cases in recursive code.
   2. Integer division
   3. null nodes in binary trees
   4. The start and end of iteration through a linked list.
4. Small test cases
5. Special cases.
   1. Test your code against null or single element values, the extreme cases, and other special cases.

### Optimize & Solve Technique #1: Look for BUD

BUD is a silly acronym for:

* Bottlenecks
* Unnecessary work
* Duplicated work

These are three of the most common things that an algorithm can "waste" time doing. You can walk through your brute force looking for these things. When you find one of them, you can focus on getting rid of it.

### Optimize & Solve Technique #2: DYI (Do it yourself)

Remember the phone book example. In real life, how would you find a name in a phone book? If you're looking
for someone called Peter, you would probably open the list a little after the middle. If it's there you would
stop looking. If not you would repeat the process either to the left or to the right depending on the letter
you found.

Try to do the same when thinking of solutions for algorithms.

### Optimize & Solve Technique #3: Simplify and Generalize

First simplify by tweaking a constraint, such as using characters instead of whole strings. Then solve the
problem for characters. Once that is working, generalize the algorithm to also work with strings.

### Optimize & Solve Technique #4: Base Case and Build

Base Case and Build algorithms often lead to natural recursive algorithms.

### Optimize & Solve Technique #5: Data Structure Brainstorm

Go through each data structure and check which could best solve the problem.

Array? Linked list? Binary tree? Heap?

Note that the more problems you do, the more developed your instinct on which data structure to apply will
be. You will also develop a more finely tuned instinct as to which of these approaches is the most useful.

### Best Conceivable Runtime (BCR)

The best conceivable runtime is, literally, the best runtime you could conceive of a solution to a problem.

If you have to search for pairs of numbers in two sorted arrays, you know that you have to look at each number in each array. That's O(N²). How can you do it faster?

I figured it out!!! :) Using the technique to do some upfront work.

Basically throw one of the arrays into a hash table.

Suppose our interviewer hits us with a question that makes us cringe: Can we do better?

The answer will be: No. Not in terms of runtime. We have achieved the fastest possible runtime. Therefore we cannot optimize the big O time. We could potentially optimize the space complexity.

This is another place where BCR is useful. It tells us that we're "done" in terms of optimizing the runtime, and we should therefore turn our efforts to the space complexity.

In fact, even without the interviewer prompting us, we should have a question mark with respect to our algorithm.

Another way we can use BCR is that if you ever reach the BCR and have O(1) additional space, then you know that you can't optimize the big O time or space.

## What Good Coding Looks like

There are lots of resources talking about clean, good code. But how is that demonstrated in an interview?

Broadly speaking, good code has the following properties:

* Correct: The code should operate correctly on all expected and unexpected inputs.
* Efficient: The code should operate as efficiently as possible in terms of both time and space. This
"efficiency" includes both the asymptotic (big O) efficiency and the practical, real-life efficiency. That is,
a constant factor might get dropped when you compute the big O time, but in real life, it can very much
matter.
* Simple: If you can do something in 10 lines instead of 100, you should. Code should be as quick as possible
for a developer to write.
* Readable: A different developer should be able to read your code and understand what it does and how it\
does it. Readable code has comments where necessary, but it implements things in an easily understandable
way. That means that your fancy code that does a bunch of complex bit shifting is not necessarily good code.
* Maintainable: Code should be reasonably adaptable to changes during the life cycle of a product and should
be easy to maintain by other developers, as well as the initial developer.

Striving for these aspects requires a balancing act. For example, it's often advisable to sacrifice some
degree of efficiency to make code more maintainable, and vice versa.

The following aspects of code are more specific ways to demonstrate the earlier list.

### Use Data Structures Generously

Sometimes just using out-of-the-box data structures to hold data for an algorithm is not the most optimal
solution, and it would probably be better to create your own data structure.

Some may think that's over-optimization. Regardless, designing your own data structure shows a thought process.
You show that weren't just trying to code something as fast as possible, but was rather trying to find the
best alternative for the situation.

So why should I use data structures generously? To seek the best way to accommodate specific data and to
demonstrate my thought process and my desire to design an optimal algorithm.

Why must I use data structures generously? To achieve better designs for algorithms. Just using built-in data
structures will not be enough in many cases. This shows that you care about your code.

When will I use data structures generously? When designing an algorithm, a functions, brainstorm all possible
data structures trying to see if existing ones will be the best fit for my scenario. If now, I will need
to write my own structure.

### Appropriate Code Reuse

Leverage code reuse. This comes in many forms including functions that can work with different arguments.
For example, instead of a function that simply converts from decimals to binaries, you should implement
a function that converts from different bases based on the argument received. So that function is more
generic and can be used in other algorithms.

Why should I make my code more reusable? To avoid reworking on the same problem. If a problem as been solved
before, that solution can be reused and made adjustable so it would solve problems with slight variations.

Why must I use that? To make my code more maintainable and useful.

When will I use that? Whenever, I'm trying to solve a problem.

### Modular

Writing module code mains separating isolated chunks of code out into their own methods. This helps keep
the code more maintainable, readable, and testable.

While some non-modular functions aren't particularly awful, the nicer thing about more modular functions is
that they are easier to test because each component can be verified separately.

As code gets more complex, it becomes increasingly important to write it in a modular way.

### Flexible and Robust

Always try to write more general code. Just because you're trying to find the winner in a tic-tac-toe gate,
doesn't mean you need to assume you only need a 3x3 matrix. Why not write the code in a more general way
that implements it for an NxN matrix?

Writing flexible, general-purpose code may also mean using variables instead of hard-codes values
or using templates / generics to solve a problem. If we can write our code to solve a more general problem,
we should.

### Error Checking

One sign of a careful coder is that they don't make assumptions about the input. Instead, they
validate that the input is what it should be, either through ASSERT statements or if-statements.

Checks like these are critical in production code.

## Don't Give Up!

Interviews are supposed to be hard. Don't get all surprised.
Show genuine excitement when facing really hard challenges.
